{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"12-XxYgyifOcAmpADJHvg7d8I1HrE84A6","authorship_tag":"ABX9TyORJu40UQkXYmAFtaezJ4yN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pBDv7OA1270r-jUUMi4BaaL5iQlIovn5"},"id":"VHYx81wt9dlC","executionInfo":{"status":"ok","timestamp":1608957036544,"user_tz":-540,"elapsed":10605,"user":{"displayName":"suebin","photoUrl":"","userId":"12546302886493983985"}},"outputId":"65dd426b-809f-444d-de1f-72227eb1ddd0"},"source":["import cv2\r\n","import numpy as np   \r\n","from keras.preprocessing.image import img_to_array\r\n","from keras.preprocessing.image import array_to_img\r\n","from keras.models import load_model\r\n","import matplotlib.pyplot as plt\r\n","\r\n","# Face detection XML load and trained model loading\r\n","face_detection = cv2.CascadeClassifier('/content/drive/MyDrive/thumbnail_generator/face_detection/haarcascade_frontalface_default.xml')\r\n","emotion_classifier = load_model('/content/drive/MyDrive/thumbnail_generator/face_detection/emotion_model.hdf5', compile=False)\r\n","EMOTIONS = [\"Angry\" ,\"Disgusting\",\"Fearful\", \"Happy\", \"Sad\", \"Surpring\", \"Neutral\"]\r\n","\r\n","frame = cv2.imread(\"/content/drive/MyDrive/thumbnail_generator/ppt/fail.png\")\r\n","\r\n","gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n","plt.imshow(gray)\r\n","\r\n","# Face detection in frame\r\n","faces = face_detection.detectMultiScale(gray,1.3, 5)\r\n","\r\n","print(len(faces))\r\n","# Perform emotion recognition only when face is detected\r\n","\r\n","print(faces)\r\n","\r\n","for j in faces:\r\n","  (fX, fY, fW, fH) = j\r\n","  roi = gray[fY:fY + fH, fX:fX + fW]\r\n","  roi = cv2.resize(roi, (48, 48))\r\n","  roi = roi.astype(\"float\") / 255.0\r\n","  roi = img_to_array(roi)\r\n","  roi = np.expand_dims(roi, axis=0)\r\n","  \r\n","  # Emotion predict\r\n","  preds = emotion_classifier.predict(roi)[0]\r\n","  emotion_probability = np.max(preds)\r\n","  label = EMOTIONS[preds.argmax()]\r\n","  \r\n","  cv2.putText(frame,  \"{}: {:.2f}%\".format(label,  emotion_probability * 100), (fX, fY - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\r\n","  cv2.rectangle(frame, (fX, fY), (fX + fW, fY + fH), (0, 0, 255), 2)\r\n","\r\n","\r\n","frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n","plt.figure(figsize = (50,20))\r\n","plt.imshow(frame)\r\n","cv2.imwrite(\"/content/drive/MyDrive/thumbnail_generator/ppt용_표정레이블4.jpg\",cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"8Cgoo8Dx-xMO"},"source":[""],"execution_count":null,"outputs":[]}]}